"""
Cap√≠tulo 5 - Ejercicio 5: Extracci√≥n de Caracter√≠sticas con SIFT
Aprende a detectar y visualizar keypoints usando SIFT (Scale-Invariant Feature Transform)
"""
import cv2
import numpy as np
import streamlit as st
from pathlib import Path
from core.utils import (
    leer_imagen,
    bgr_to_rgb,
    mostrar_imagen_streamlit,
    comparar_imagenes,
    cargar_imagen_desde_upload
)
from ui.layout import crear_seccion, mostrar_codigo, crear_alerta
from ui.widgets import (
    control_slider,
    panel_control,
    checkbox_simple,
    selector_opciones,
    boton_accion,
    info_tooltip,
    entrada_numero
)

# Verificar disponibilidad de SIFT
try:
    # OpenCV >= 3.4.2
    sift_test = cv2.SIFT_create()
    SIFT_AVAILABLE = True
    SIFT_MODULE = "cv2.SIFT_create()"
except AttributeError:
    try:
        # OpenCV contrib (xfeatures2d)
        sift_test = cv2.xfeatures2d.SIFT_create()
        SIFT_AVAILABLE = True
        SIFT_MODULE = "cv2.xfeatures2d.SIFT_create()"
    except (AttributeError, cv2.error):
        SIFT_AVAILABLE = False
        SIFT_MODULE = None


def run():
    """Funci√≥n principal del ejercicio."""
    
    # Header del ejercicio
    st.title("Extracci√≥n de Caracter√≠sticas SIFT")
    st.markdown("""
    Detecta y visualiza keypoints (puntos caracter√≠sticos) en im√°genes usando **SIFT** 
    (Scale-Invariant Feature Transform), uno de los algoritmos m√°s robustos para 
    detecci√≥n de caracter√≠sticas invariantes a escala y rotaci√≥n.
    """)
    
    st.markdown("---")
    
    # Verificar disponibilidad de SIFT
    if not verificar_sift():
        return
    
    # Tabs principales
    tab1, tab2, tab3, tab4 = st.tabs([
        "Detecci√≥n de Keypoints",
        "An√°lisis de Descriptores",
        "Comparaci√≥n de Par√°metros",
        "Teor√≠a"
    ])
    
    with tab1:
        deteccion_keypoints()
    
    with tab2:
        analisis_descriptores()
    
    with tab3:
        comparacion_parametros()
    
    with tab4:
        mostrar_teoria()


def verificar_sift():
    """Verifica que SIFT est√© disponible."""
    
    if not SIFT_AVAILABLE:
        st.error("SIFT no est√° disponible en tu instalaci√≥n de OpenCV")
        
        st.markdown("""
        ### üîß Soluciones posibles:
        
        **Opci√≥n 1: Instalar OpenCV con soporte SIFT (Recomendado para uso educativo)**
        ```bash
        pip uninstall opencv-python opencv-contrib-python
        pip install opencv-contrib-python
        ```
        
        **Opci√≥n 2: Usar OpenCV >= 4.4.0**
        
        A partir de OpenCV 4.4.0, SIFT ya no est√° bajo patente y est√° disponible 
        en la versi√≥n est√°ndar:
        ```bash
        pip install opencv-python>=4.4.0
        ```
        
        **Nota sobre la Patente:**
        
        SIFT estuvo patentado hasta marzo de 2020. Para **uso comercial** antes de esa fecha, 
        se requer√≠a licencia. Para **uso educativo y de investigaci√≥n**, generalmente estaba permitido.
        
        **Alternativas libres de patentes:**
        - **ORB** (Oriented FAST and Rotated BRIEF) - M√°s r√°pido, libre
        - **AKAZE** - Precisi√≥n similar, libre
        - **BRISK** - R√°pido y robusto, libre
        """)
        
        if st.button("Intentar nuevamente"):
            st.rerun()
        
        return False
    
    st.success(f"SIFT disponible: `{SIFT_MODULE}`")
    return True


def deteccion_keypoints():
    """Detecci√≥n y visualizaci√≥n de keypoints."""
    
    crear_seccion("Detecci√≥n de Keypoints", "")
    
    st.markdown("""
    Los **keypoints** son puntos de inter√©s √∫nicos en una imagen (esquinas, bordes, regiones distintivas) 
    que pueden ser detectados de manera confiable incluso cuando la imagen es escalada, rotada o 
    ligeramente deformada.
    """)
    
    # Sidebar para controles
    with st.sidebar:
        st.markdown("### Configuraci√≥n")
        
        # Selector de imagen
        opcion_imagen = selector_opciones(
            "Fuente de imagen",
            ["Imagen de ejemplo 1", "Imagen de ejemplo 2", "Subir imagen"],
            key="img_source_sift"
        )
        
        if opcion_imagen == "Subir imagen":
            from ui.widgets import subir_archivo
            archivo = subir_archivo(
                ["png", "jpg", "jpeg"],
                "Sube una imagen",
                key="upload_sift"
            )
            if archivo:
                img = cargar_imagen_desde_upload(archivo)
            else:
                st.warning("Por favor sube una imagen")
                return
        else:
            # Usar im√°genes de ejemplo
            img_paths = {
                "Imagen de ejemplo 1": "data/images/puente.jpg",
                "Imagen de ejemplo 2": "data/images/edificio.jpg"
            }
            img_path = Path(img_paths.get(opcion_imagen, img_paths["Imagen de ejemplo 1"]))
            
            if img_path.exists():
                img = leer_imagen(str(img_path))
            else:
                st.warning(f"No se encontr√≥ {img_path}. Por favor sube tu propia imagen.")
                return
        
        if img is None:
            return
        
        st.markdown("---")
        st.markdown("### Par√°metros SIFT")
        
        # Par√°metros SIFT
        n_features = entrada_numero(
            "N√∫mero de caracter√≠sticas",
            0, 10000, 0, 100,
            formato="%d",
            ayuda="0 = detectar todas las caracter√≠sticas posibles",
            key="n_features"
        )
        
        n_octave_layers = control_slider(
            "Capas por octava",
            1, 10, 3,
            "N√∫mero de capas en cada octava de la pir√°mide de escala",
            key="n_octave_layers"
        )
        
        contrast_threshold = st.sidebar.number_input(
            "Umbral de contraste",
            min_value=0.001,
            max_value=0.5,
            value=0.04,
            step=0.01,
            format="%.3f",
            help="Umbral para filtrar keypoints de bajo contraste",
            key="contrast_threshold"
        )
        
        edge_threshold = entrada_numero(
            "Umbral de borde",
            1.0, 50.0, 10.0, 1.0,
            formato="%.1f",
            ayuda="Umbral para filtrar keypoints en bordes",
            key="edge_threshold"
        )
        
        sigma = st.sidebar.number_input(
            "Sigma (œÉ)",
            min_value=0.5,
            max_value=5.0,
            value=1.6,
            step=0.1,
            format="%.1f",
            help="Sigma del Gaussian aplicado a la imagen base",
            key="sigma"
        )
        
        st.markdown("---")
        st.markdown("### Opciones de Visualizaci√≥n")
        
        draw_mode = selector_opciones(
            "Modo de dibujo",
            ["Keypoints ricos", "Keypoints simples", "Solo ubicaciones"],
            key="draw_mode"
        )
        
        color_mode = selector_opciones(
            "Color de keypoints",
            ["Aleatorio", "Verde", "Azul", "Rojo", "Por escala"],
            key="color_mode"
        )
        
        mostrar_info = checkbox_simple(
            "Mostrar informaci√≥n detallada",
            True,
            key="show_info"
        )
    
    # Convertir a escala de grises
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Crear detector SIFT
    sift = crear_sift_detector(
        n_features,
        n_octave_layers,
        contrast_threshold,
        edge_threshold,
        sigma
    )
    
    # Detectar keypoints
    with st.spinner("Detectando keypoints..."):
        keypoints = sift.detect(gray, None)
    
    # Dibujar keypoints
    img_keypoints = img.copy()
    img_keypoints = dibujar_keypoints(
        img_keypoints,
        keypoints,
        draw_mode,
        color_mode
    )
    
    # Mostrar resultados
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Imagen Original**")
        mostrar_imagen_streamlit(img, "")
    
    with col2:
        st.markdown(f"**Keypoints Detectados ({len(keypoints)})**")
        mostrar_imagen_streamlit(img_keypoints, "")
    
    # Informaci√≥n detallada
    if mostrar_info and len(keypoints) > 0:
        mostrar_informacion_keypoints(keypoints)
    
    # Opciones de an√°lisis adicional
    st.markdown("---")
    crear_seccion("An√°lisis Adicional", "")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("Ver distribuci√≥n de escalas", use_container_width=True):
            mostrar_distribucion_escalas(keypoints)
    
    with col2:
        if st.button("Ver distribuci√≥n de orientaciones", use_container_width=True):
            mostrar_distribucion_orientaciones(keypoints)
    
    with col3:
        if st.button("Ver mapa de calor", use_container_width=True):
            mostrar_mapa_calor(img, keypoints)
    
    # Bot√≥n de descarga
    if len(keypoints) > 0 and boton_accion("Guardar resultado", key="save_sift"):
        guardar_resultado(img_keypoints, "sift_keypoints.jpg")


def analisis_descriptores():
    """An√°lisis de descriptores SIFT."""
    
    crear_seccion("An√°lisis de Descriptores", "")
    
    st.markdown("""
    Los **descriptores** son vectores num√©ricos que describen la regi√≥n alrededor de cada keypoint.
    SIFT genera descriptores de **128 dimensiones** que son robustos a cambios de iluminaci√≥n,
    escala y rotaci√≥n.
    """)
    
    # Cargar imagen
    with st.sidebar:
        st.markdown("### Configuraci√≥n")
        
        opcion_imagen = selector_opciones(
            "Fuente de imagen",
            ["Imagen de ejemplo 1", "Imagen de ejemplo 2", "Subir imagen"],
            key="img_source_desc"
        )
        
        if opcion_imagen == "Subir imagen":
            from ui.widgets import subir_archivo
            archivo = subir_archivo(
                ["png", "jpg", "jpeg"],
                "Sube una imagen",
                key="upload_desc"
            )
            if archivo:
                img = cargar_imagen_desde_upload(archivo)
            else:
                st.warning("Por favor sube una imagen")
                return
        else:
            img_paths = {
                "Imagen de ejemplo 1": "data/images/puente.jpg",
                "Imagen de ejemplo 2": "data/images/edificio.jpg"
            }
            img_path = Path(img_paths.get(opcion_imagen, img_paths["Imagen de ejemplo 1"]))
            
            if img_path.exists():
                img = leer_imagen(str(img_path))
            else:
                st.warning(f"No se encontr√≥ la imagen de ejemplo")
                return
        
        if img is None:
            return
        
        max_keypoints_display = control_slider(
            "Keypoints a mostrar",
            5, 50, 10,
            "N√∫mero de keypoints para visualizar descriptores",
            key="max_kp_display"
        )
    
    # Convertir a escala de grises
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Crear detector SIFT y calcular descriptores
    sift = crear_sift_detector()
    
    with st.spinner("Calculando keypoints y descriptores..."):
        keypoints, descriptors = sift.detectAndCompute(gray, None)
    
    if descriptors is None or len(keypoints) == 0:
        st.warning("No se detectaron keypoints en esta imagen")
        return
    
    # Mostrar estad√≠sticas generales
    st.markdown("### Estad√≠sticas Generales")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Keypoints", len(keypoints))
    
    with col2:
        st.metric("Dimensiones", descriptors.shape[1])
    
    with col3:
        avg_response = np.mean([kp.response for kp in keypoints])
        st.metric("Respuesta promedio", f"{avg_response:.3f}")
    
    with col4:
        avg_size = np.mean([kp.size for kp in keypoints])
        st.metric("Tama√±o promedio", f"{avg_size:.1f}px")
    
    st.markdown("---")
    
    # Visualizar algunos descriptores
    st.markdown("### Visualizaci√≥n de Descriptores")
    
    st.info(f"Mostrando los primeros {min(max_keypoints_display, len(keypoints))} keypoints m√°s fuertes")
    
    # Ordenar keypoints por respuesta
    keypoints_sorted = sorted(keypoints, key=lambda x: x.response, reverse=True)
    keypoints_top = keypoints_sorted[:max_keypoints_display]
    indices_top = [keypoints.index(kp) for kp in keypoints_top]
    
    # Dibujar keypoints seleccionados
    img_selected = img.copy()
    for i, kp in enumerate(keypoints_top):
        color = (0, 255, 0) if i == 0 else (255, 0, 0)
        cv2.circle(img_selected, (int(kp.pt[0]), int(kp.pt[1])), 
                  int(kp.size), color, 2)
        cv2.putText(img_selected, str(i+1), 
                   (int(kp.pt[0])-10, int(kp.pt[1])-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    mostrar_imagen_streamlit(img_selected, f"Keypoints seleccionados (Verde = m√°s fuerte)")
    
    st.markdown("---")
    
    # An√°lisis estad√≠stico de descriptores
    st.markdown("### An√°lisis Estad√≠stico")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Estad√≠sticas de Descriptores**")
        st.code(f"""
Media global: {np.mean(descriptors):.2f}
Desviaci√≥n est√°ndar: {np.std(descriptors):.2f}
Valor m√≠nimo: {np.min(descriptors):.2f}
Valor m√°ximo: {np.max(descriptors):.2f}
Mediana: {np.median(descriptors):.2f}
        """)
    
    with col2:
        st.markdown("**Propiedades del Mejor Keypoint**")
        best_kp = keypoints_top[0]
        st.code(f"""
Posici√≥n: ({int(best_kp.pt[0])}, {int(best_kp.pt[1])})
Tama√±o: {best_kp.size:.2f}px
√Ångulo: {best_kp.angle:.2f}¬∞
Respuesta: {best_kp.response:.4f}
Octava: {best_kp.octave}
        """)


def comparacion_parametros():
    """Comparaci√≥n de diferentes configuraciones de par√°metros."""
    
    crear_seccion("Comparaci√≥n de Par√°metros", "")
    
    st.markdown("""
    Observa c√≥mo diferentes par√°metros de SIFT afectan la cantidad y calidad 
    de los keypoints detectados.
    """)
    
    # Cargar imagen
    img_path = Path("data/images/puente.jpg")
    if not img_path.exists():
        img_path = Path("data/images/edificio.jpg")
    
    if img_path.exists():
        img = leer_imagen(str(img_path))
    else:
        st.warning("No se encontr√≥ imagen de ejemplo")
        return
    
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    st.markdown("### Efecto del Umbral de Contraste")
    
    contrast_values = [0.02, 0.04, 0.08, 0.12]
    
    cols = st.columns(len(contrast_values))
    
    for i, contrast in enumerate(contrast_values):
        with cols[i]:
            sift = crear_sift_detector(contrast_threshold=contrast)
            keypoints = sift.detect(gray, None)
            
            img_temp = img.copy()
            img_temp = dibujar_keypoints(img_temp, keypoints, "Keypoints ricos", "Verde")
            
            st.markdown(f"**Contraste: {contrast}**")
            st.caption(f"{len(keypoints)} keypoints")
            mostrar_imagen_streamlit(img_temp, "")
    
    st.markdown("---")
    st.markdown("### Efecto de las Capas por Octava")
    
    octave_values = [2, 3, 4, 5]
    
    cols = st.columns(len(octave_values))
    
    for i, octaves in enumerate(octave_values):
        with cols[i]:
            sift = crear_sift_detector(n_octave_layers=octaves)
            keypoints = sift.detect(gray, None)
            
            img_temp = img.copy()
            img_temp = dibujar_keypoints(img_temp, keypoints, "Keypoints ricos", "Azul")
            
            st.markdown(f"**Octavas: {octaves}**")
            st.caption(f"{len(keypoints)} keypoints")
            mostrar_imagen_streamlit(img_temp, "")
    
    st.markdown("---")
    
    # Tabla comparativa
    st.markdown("### Tabla Comparativa")
    
    configs = [
        ("Muy permisivo", 0, 3, 0.02, 10, 1.6),
        ("Est√°ndar", 0, 3, 0.04, 10, 1.6),
        ("Restrictivo", 0, 3, 0.08, 15, 1.6),
        ("Muy restrictivo", 0, 3, 0.12, 20, 1.6),
    ]
    
    results = []
    
    for nombre, nf, no, ct, et, s in configs:
        sift = crear_sift_detector(nf, no, ct, et, s)
        keypoints = sift.detect(gray, None)
        avg_response = np.mean([kp.response for kp in keypoints]) if keypoints else 0
        avg_size = np.mean([kp.size for kp in keypoints]) if keypoints else 0
        
        results.append({
            "Configuraci√≥n": nombre,
            "Keypoints": len(keypoints),
            "Respuesta Promedio": f"{avg_response:.4f}",
            "Tama√±o Promedio": f"{avg_size:.1f}px",
            "Umbral Contraste": ct,
            "Umbral Borde": et
        })
    
    import pandas as pd
    df = pd.DataFrame(results)
    st.dataframe(df, use_container_width=True)
    
    st.info("""
    **Observaciones:**
    - Umbrales m√°s bajos ‚Üí M√°s keypoints (incluye puntos d√©biles)
    - Umbrales m√°s altos ‚Üí Menos keypoints (solo los m√°s robustos)
    - M√°s capas por octava ‚Üí Mejor detecci√≥n multi-escala pero m√°s lento
    """)


def mostrar_teoria():
    """Secci√≥n te√≥rica sobre SIFT."""
    
    crear_seccion("Teor√≠a: Scale-Invariant Feature Transform (SIFT)", "")
    
    st.markdown("""
    ### ¬øQu√© es SIFT?
    
    **SIFT** (Scale-Invariant Feature Transform) es un algoritmo de visi√≥n por computadora 
    desarrollado por **David Lowe en 1999** (publicado en 2004) para detectar y describir 
    caracter√≠sticas locales en im√°genes.
    
    ### Caracter√≠sticas Principales
    
    #### **Invarianzas:**
    - **Escala**: Detecta caracter√≠sticas independientemente del tama√±o
    - **Rotaci√≥n**: No afectado por la orientaci√≥n de la imagen
    - **Iluminaci√≥n**: Robusto a cambios de brillo y contraste
    - **Punto de vista**: Parcialmente invariante a cambios de perspectiva
    - **Ruido**: Resistente al ruido en la imagen
    
    ### Pipeline de SIFT (4 Etapas)
    
    #### **1. Detecci√≥n de Extremos en Espacio-Escala**
    
    ```
    Pir√°mide Gaussian ‚Üí Diferencia de Gaussianas (DoG) ‚Üí Extremos locales
    ```
    
    - Crea pir√°mide de im√°genes en diferentes escalas
    - Aplica Diferencia de Gaussianas (DoG): aproximaci√≥n del Laplaciano
    - Busca m√°ximos y m√≠nimos locales en el espacio 3D (x, y, escala)
    
    #### **2. Localizaci√≥n Precisa de Keypoints**
    
    - Elimina puntos de bajo contraste (inestables)
    - Elimina puntos en bordes (usando matriz Hessiana)
    - Refina la posici√≥n mediante interpolaci√≥n sub-pixel
    
    #### **3. Asignaci√≥n de Orientaci√≥n**
    
    - Calcula histograma de orientaciones en vecindad del keypoint
    - Asigna orientaci√≥n(es) dominante(s)
    - Hace al descriptor invariante a rotaci√≥n
    
    #### **4. Generaci√≥n de Descriptores**
    
    - Regi√≥n de 16x16 p√≠xeles alrededor del keypoint
    - Dividida en 4x4 sub-regiones
    - Histograma de 8 orientaciones por sub-regi√≥n
    - **Resultado: Vector de 128 dimensiones (4√ó4√ó8)**
    
    ### Par√°metros de SIFT
    
    ```python
    sift = cv2.SIFT_create(
        nfeatures=0,           # 0 = ilimitado
        nOctaveLayers=3,       # Capas por octava
        contrastThreshold=0.04, # Umbral de contraste
        edgeThreshold=10,      # Umbral de borde
        sigma=1.6              # Sigma del Gaussian
    )
    ```
    
    #### **nfeatures**
    - N√∫mero m√°ximo de caracter√≠sticas a retener
    - 0 = detectar todas las posibles
    - √ötil para limitar tiempo de procesamiento
    
    #### **nOctaveLayers**
    - N√∫mero de capas por octava en pir√°mide DoG
    - M√°s capas = mejor detecci√≥n multi-escala
    - Valor t√≠pico: 3
    - Rango com√∫n: 2-5
    
    #### **contrastThreshold**
    - Filtra keypoints de bajo contraste
    - Mayor valor = menos keypoints, m√°s robustos
    - Valor t√≠pico: 0.04
    - Rango: 0.01 - 0.15
    
    #### **edgeThreshold**
    - Filtra keypoints en bordes (ratio Hessiana)
    - Mayor valor = menos rechazo de bordes
    - Valor t√≠pico: 10
    - Rango: 5 - 20
    
    #### **sigma**
    - Desviaci√≥n est√°ndar del Gaussian base
    - Controla suavizado inicial
    - Valor t√≠pico: 1.6
    - Rango: 1.0 - 2.0
    
    ### Propiedades de un Keypoint
    
    Cada keypoint detectado contiene:
    
    ```python
    keypoint.pt        # (x, y) coordenadas
    keypoint.size      # Di√°metro del √°rea significativa
    keypoint.angle     # Orientaci√≥n en grados [0, 360)
    keypoint.response  # Fuerza de la respuesta (calidad)
    keypoint.octave    # Octava donde fue detectado
    keypoint.class_id  # ID de clase (para clasificaci√≥n)
    ```
    
    ### Descriptor SIFT (128D)
    
    El descriptor es un vector de 128 valores que describe la regi√≥n:
    
    ```
    [v‚ÇÄ, v‚ÇÅ, v‚ÇÇ, ..., v‚ÇÅ‚ÇÇ‚Çá]
    
    Organizado como: 4√ó4 sub-regiones √ó 8 orientaciones = 128
    ```
    
    **Propiedades:**
    - Normalizado para invarianza a iluminaci√≥n
    - Robusto a deformaciones geom√©tricas peque√±as
    - √önico y distintivo para matching
    
    ### Diferencia de Gaussianas (DoG)
    
    ```
    DoG(x, y, œÉ) = G(x, y, kœÉ) - G(x, y, œÉ)
    ```
    
    Donde:
    - G = Filtro Gaussiano
    - k = Factor de escala constante
    - œÉ = Desviaci√≥n est√°ndar
    
    **DoG aproxima la Laplaciana normalizada de Gaussiana**, que es √≥ptima 
    para detecci√≥n de blobs en espacio-escala.
    
    ### Ventajas de SIFT
    
    **Muy robusto** a transformaciones
    **Descriptores distintivos** - excelente para matching
    **Bien establecido** - ampliamente investigado y validado
    **Implementaci√≥n madura** en OpenCV
    **Funciona en escenas complejas**
    
    ### Desventajas de SIFT
    
    **Computacionalmente costoso** comparado con alternativas modernas
    **No funciona bien** en im√°genes con repetici√≥n de patrones
    **Descriptores grandes** (128D) - m√°s memoria
    **Patente** (expir√≥ en marzo 2020, ahora libre)
    
    ### Alternativas a SIFT
    
    | Algoritmo | Velocidad | Precisi√≥n | Descriptores | Libre |
    |-----------|-----------|-----------|--------------|-------|
    | **SIFT** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 128D | ‚úÖ (desde 2020) |
    | **SURF** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 64D/128D | ‚ùå (patentado) |
    | **ORB** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 256 bits | ‚úÖ |
    | **AKAZE** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 61D-486D | ‚úÖ |
    | **BRISK** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 512 bits | ‚úÖ |
    
    ### Aplicaciones de SIFT
    
    - **Reconocimiento de objetos** - Identificar objetos en escenas
    - **Panoramas** - Crear im√°genes panor√°micas (image stitching)
    - **SLAM** (Simultaneous Localization and Mapping) - Robots y drones
    - **Reconocimiento facial** - Matching de rostros
    - **Tracking** - Seguimiento de objetos en video
    - **Reconstrucci√≥n 3D** - Structure from Motion
    - **Watermarking** - Marcas de agua robustas
    - **Realidad Aumentada** - Detectar y trackear marcadores
    
    ### Tips para Mejores Resultados
    
    **Textura rica** - SIFT funciona mejor con texturas detalladas
    **Buenos bordes** - Esquinas y bordes fuertes mejoran detecci√≥n
    **Evitar superficies planas** - Pocas caracter√≠sticas detectables
    **Buena iluminaci√≥n** - Mejora la calidad de los descriptores
    **Im√°genes n√≠tidas** - El blur reduce la cantidad de keypoints
    
    ### Optimizaci√≥n de Rendimiento
    
    ```python
    # Para aplicaciones en tiempo real:
    sift = cv2.SIFT_create(
        nfeatures=500,          # Limitar n√∫mero de caracter√≠sticas
        nOctaveLayers=3,        # No aumentar sin necesidad
        contrastThreshold=0.06  # Aumentar para menos keypoints
    )
    
    # Para matching preciso:
    sift = cv2.SIFT_create(
        nfeatures=0,            # Sin l√≠mite
        nOctaveLayers=4,        # M√°s escalas
        contrastThreshold=0.03  # M√°s permisivo
    )
    ```
    
    ### Comparaci√≥n: SIFT vs Detecci√≥n de Esquinas
    
    | Aspecto | Harris Corners | SIFT |
    |---------|---------------|------|
    | **Tipo** | Solo detecci√≥n | Detecci√≥n + Descripci√≥n |
    | **Escala** | ‚ùå No invariante | ‚úÖ Invariante |
    | **Rotaci√≥n** | ‚ùå No invariante | ‚úÖ Invariante |
    | **Descriptores** | ‚ùå No incluye | ‚úÖ 128D vector |
    | **Velocidad** | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚ö°‚ö° |
    | **Matching** | Dif√≠cil | F√°cil |
    
    ### Historia y Patente
    
    - **1999**: David Lowe presenta SIFT
    - **2004**: Publicaci√≥n completa del paper
    - **2004-2020**: Bajo patente (uso comercial restringido)
    - **Marzo 2020**: Patente expira - ahora completamente libre
    - **OpenCV 4.4.0+**: SIFT incluido en versi√≥n est√°ndar
    
    ### Paper Original
    
    **"Distinctive Image Features from Scale-Invariant Keypoints"**
    David G. Lowe, 2004
    
    *Uno de los papers m√°s citados en Computer Vision (>50,000 citaciones)*
    """)
    
    st.markdown("---")
    crear_seccion("C√≥digo de Ejemplo", "")
    
    codigo = '''import cv2
import numpy as np

# Cargar imagen
img = cv2.imread('image.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Crear detector SIFT
sift = cv2.SIFT_create()

# Opci√≥n 1: Solo detectar keypoints
keypoints = sift.detect(gray, None)

# Opci√≥n 2: Detectar y computar descriptores
keypoints, descriptors = sift.detectAndCompute(gray, None)

# Dibujar keypoints
img_keypoints = cv2.drawKeypoints(
    img, 
    keypoints, 
    None,
    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS
)

# Mostrar informaci√≥n
print(f"Keypoints detectados: {len(keypoints)}")
print(f"Dimensi√≥n descriptores: {descriptors.shape}")

# Propiedades del primer keypoint
kp = keypoints[0]
print(f"Posici√≥n: {kp.pt}")
print(f"Tama√±o: {kp.size}")
print(f"√Ångulo: {kp.angle}")
print(f"Respuesta: {kp.response}")

# Visualizar
cv2.imshow('SIFT Features', img_keypoints)
cv2.waitKey(0)
cv2.destroyAllWindows()
'''
    
    mostrar_codigo(codigo, "python")
    
    st.markdown("---")
    
    # Ejemplo de matching
    crear_seccion("Ejemplo: Matching de Keypoints", "")
    
    codigo_matching = '''import cv2
import numpy as np

# Cargar dos im√°genes
img1 = cv2.imread('image1.jpg', 0)
img2 = cv2.imread('image2.jpg', 0)

# Detectar y computar
sift = cv2.SIFT_create()
kp1, des1 = sift.detectAndCompute(img1, None)
kp2, des2 = sift.detectAndCompute(img2, None)

# Matcher usando FLANN
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
search_params = dict(checks=50)

flann = cv2.FlannBasedMatcher(index_params, search_params)
matches = flann.knnMatch(des1, des2, k=2)

# Ratio test (Lowe's ratio)
good_matches = []
for m, n in matches:
    if m.distance < 0.7 * n.distance:
        good_matches.append(m)

# Dibujar matches
img_matches = cv2.drawMatches(
    img1, kp1, img2, kp2, good_matches, None,
    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
)

print(f"Matches encontrados: {len(good_matches)}")
cv2.imshow('Matches', img_matches)
cv2.waitKey(0)
'''
    
    mostrar_codigo(codigo_matching, "python")


# ============================================================================
# FUNCIONES AUXILIARES
# ============================================================================

def crear_sift_detector(n_features=0, n_octave_layers=3, 
                       contrast_threshold=0.04, edge_threshold=10, sigma=1.6):
    """Crea un detector SIFT con los par√°metros especificados."""
    try:
        # OpenCV >= 4.4.0
        sift = cv2.SIFT_create(
            nfeatures=n_features,
            nOctaveLayers=n_octave_layers,
            contrastThreshold=contrast_threshold,
            edgeThreshold=edge_threshold,
            sigma=sigma
        )
    except AttributeError:
        # OpenCV con contrib
        sift = cv2.xfeatures2d.SIFT_create(
            nfeatures=n_features,
            nOctaveLayers=n_octave_layers,
            contrastThreshold=contrast_threshold,
            edgeThreshold=edge_threshold,
            sigma=sigma
        )
    
    return sift


def dibujar_keypoints(img, keypoints, draw_mode, color_mode):
    """Dibuja keypoints en la imagen seg√∫n el modo especificado."""
    
    # Determinar flags
    if draw_mode == "Keypoints ricos":
        flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS
    elif draw_mode == "Keypoints simples":
        flags = cv2.DRAW_MATCHES_FLAGS_DEFAULT
    else:  # Solo ubicaciones
        flags = 0
    
    # Determinar color
    if color_mode == "Aleatorio":
        color = None
    elif color_mode == "Verde":
        color = (0, 255, 0)
    elif color_mode == "Azul":
        color = (255, 0, 0)
    elif color_mode == "Rojo":
        color = (0, 0, 255)
    elif color_mode == "Por escala":
        # Colorear seg√∫n tama√±o (escala)
        img_result = img.copy()
        for kp in keypoints:
            # Mapear tama√±o a color (azul=peque√±o, rojo=grande)
            size_normalized = min(kp.size / 50.0, 1.0)
            color_kp = (
                int(255 * size_normalized),
                0,
                int(255 * (1 - size_normalized))
            )
            cv2.circle(img_result, (int(kp.pt[0]), int(kp.pt[1])), 
                      int(kp.size), color_kp, 2)
            
            # Dibujar orientaci√≥n
            if draw_mode == "Keypoints ricos":
                angle_rad = np.deg2rad(kp.angle)
                x2 = int(kp.pt[0] + kp.size * np.cos(angle_rad))
                y2 = int(kp.pt[1] + kp.size * np.sin(angle_rad))
                cv2.line(img_result, (int(kp.pt[0]), int(kp.pt[1])), 
                        (x2, y2), color_kp, 2)
        
        return img_result
    else:
        color = None
    
    # Dibujar
    img_result = cv2.drawKeypoints(img, keypoints, None, color, flags)
    
    return img_result


def mostrar_informacion_keypoints(keypoints):
    """Muestra informaci√≥n detallada sobre los keypoints."""
    
    st.markdown("### Informaci√≥n Detallada")
    
    # Estad√≠sticas generales
    sizes = [kp.size for kp in keypoints]
    responses = [kp.response for kp in keypoints]
    angles = [kp.angle for kp in keypoints]
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**Tama√±os**")
        st.code(f"""
Promedio: {np.mean(sizes):.2f}px
M√≠nimo: {np.min(sizes):.2f}px
M√°ximo: {np.max(sizes):.2f}px
Std Dev: {np.std(sizes):.2f}px
        """)
    
    with col2:
        st.markdown("**Respuestas**")
        st.code(f"""
Promedio: {np.mean(responses):.4f}
M√≠nimo: {np.min(responses):.4f}
M√°ximo: {np.max(responses):.4f}
Std Dev: {np.std(responses):.4f}
        """)
    
    with col3:
        st.markdown("**Orientaciones**")
        st.code(f"""
Promedio: {np.mean(angles):.2f}¬∞
M√≠nimo: {np.min(angles):.2f}¬∞
M√°ximo: {np.max(angles):.2f}¬∞
Std Dev: {np.std(angles):.2f}¬∞
        """)
    
    # Top 5 keypoints m√°s fuertes
    st.markdown("---")
    st.markdown("### Top 5 Keypoints M√°s Fuertes")
    
    keypoints_sorted = sorted(keypoints, key=lambda x: x.response, reverse=True)[:5]
    
    for i, kp in enumerate(keypoints_sorted, 1):
        st.markdown(f"""
**#{i}** - Posici√≥n: ({int(kp.pt[0])}, {int(kp.pt[1])}) | 
Tama√±o: {kp.size:.1f}px | √Ångulo: {kp.angle:.1f}¬∞ | 
Respuesta: {kp.response:.4f}
        """)


def mostrar_distribucion_escalas(keypoints):
    """Muestra la distribuci√≥n de escalas de los keypoints."""
    
    sizes = [kp.size for kp in keypoints]
    
    st.markdown("### Distribuci√≥n de Escalas")
    
    # Crear histograma
    hist, bins = np.histogram(sizes, bins=20)
    
    # Mostrar con Streamlit
    import pandas as pd
    df = pd.DataFrame({
        'Tama√±o (px)': [(bins[i] + bins[i+1])/2 for i in range(len(bins)-1)],
        'Frecuencia': hist
    })
    
    st.bar_chart(df.set_index('Tama√±o (px)'))
    
    st.info(f"""
    **An√°lisis:**
    - Rango de tama√±os: {min(sizes):.1f}px - {max(sizes):.1f}px
    - Tama√±o m√°s com√∫n: {bins[np.argmax(hist)]:.1f}px
    - Total de keypoints: {len(keypoints)}
    """)


def mostrar_distribucion_orientaciones(keypoints):
    """Muestra la distribuci√≥n de orientaciones de los keypoints."""
    
    angles = [kp.angle for kp in keypoints]
    
    st.markdown("### Distribuci√≥n de Orientaciones")
    
    # Crear histograma circular (simplificado)
    hist, bins = np.histogram(angles, bins=36)  # 10¬∞ por bin
    
    import pandas as pd
    df = pd.DataFrame({
        '√Ångulo (¬∞)': [(bins[i] + bins[i+1])/2 for i in range(len(bins)-1)],
        'Frecuencia': hist
    })
    
    st.bar_chart(df.set_index('√Ångulo (¬∞)'))
    
    st.info(f"""
    **An√°lisis:**
    - Orientaci√≥n promedio: {np.mean(angles):.1f}¬∞
    - Desviaci√≥n est√°ndar: {np.std(angles):.1f}¬∞
    - Total de keypoints: {len(keypoints)}
    """)


def mostrar_mapa_calor(img, keypoints):
    """Muestra un mapa de calor de la densidad de keypoints."""
    
    st.markdown("### Mapa de Calor de Keypoints")
    
    # Crear imagen de densidad
    heatmap = np.zeros(img.shape[:2], dtype=np.float32)
    
    for kp in keypoints:
        x, y = int(kp.pt[0]), int(kp.pt[1])
        size = int(kp.size)
        response = kp.response
        
        # Agregar Gaussian blob
        y_min = max(0, y - size)
        y_max = min(heatmap.shape[0], y + size)
        x_min = max(0, x - size)
        x_max = min(heatmap.shape[1], x + size)
        
        heatmap[y_min:y_max, x_min:x_max] += response
    
    # Normalizar
    heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)
    heatmap = heatmap.astype(np.uint8)
    
    # Aplicar colormap
    heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
    
    # Superponer
    overlay = cv2.addWeighted(img, 0.5, heatmap_colored, 0.5, 0)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Mapa de Calor Puro**")
        mostrar_imagen_streamlit(heatmap_colored, "")
    
    with col2:
        st.markdown("**Superposici√≥n**")
        mostrar_imagen_streamlit(overlay, "")
    
    st.info("""
    **Interpretaci√≥n:**
    - Rojo/Amarillo = Alta densidad de keypoints fuertes
    - Verde/Azul = Baja densidad de keypoints
    - Negro = Sin keypoints
    """)


def guardar_resultado(img, filename):
    """Guarda la imagen resultado."""
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    output_path = output_dir / filename
    cv2.imwrite(str(output_path), img)
    
    st.success(f"Imagen guardada en: {output_path}")


if __name__ == "__main__":
    run()